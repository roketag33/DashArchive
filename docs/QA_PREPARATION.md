# üéì Pr√©paration Questions/R√©ponses - Soutenance DashArchive

Ce document liste les questions probables que ton professeur ou le jury pourrait poser, avec des √©l√©ments de r√©ponse techniques et pertinents.

## üèóÔ∏è Architecture & Choix Techniques

### Q: Pourquoi avoir choisi Electron alors qu'il est r√©put√© lourd ?

**R:**

- **N√©cessit√© d'acc√®s Syst√®me bas niveau :** DashArchive doit manipuler le syst√®me de fichiers (d√©placer, renommer, scanner) et utiliser des modules natifs (C++) comme `@parcel/watcher` pour la surveillance performante. Un simple site Web ne peut pas faire √ßa.
- **Support GPU Local :** Electron permet d'acc√©der facilement au GPU via WebGPU pour faire tourner Llama 3 localement.
- **√âcosyst√®me unifi√© :** Permet d'utiliser React/TypeScript pour l'UI tout en ayant un backend Node.js puissant.

### Q: Expliquez votre architecture multi-processus. Pourquoi un Worker s√©par√© ?

**R:**

- L'application est divis√©e en 3 processus principaux :
  1.  **Main Process :** G√®re le cycle de vie de l'app, les fen√™tres, et les op√©rations syst√®me critiques (Fichier, DB).
  2.  **Renderer :** L'interface utilisateur (React). Elle doit rester fluide √† 60fps.
  3.  **AI Worker (Hidden Renderer) :** C'est la cl√©. Les mod√®les IA (Llama 3) sont lourds et peuvent bloquer le fil d'ex√©cution. En les isolant dans une fen√™tre cach√©e d√©di√©e, l'UI ne g√®le jamais, m√™me quand l'IA "r√©fl√©chit" √† fond.
- Communication via **IPC (Inter-Process Communication)** asynchrone s√©curis√©.

### Q: Comment garantissez-vous la s√©curit√© des √©changes entre ces processus ?

**R:**

- Utilisation de `contextIsolation: true` et `nodeIntegration: false`.
- **Preload Bridge :** Le Renderer n'a pas acc√®s direct √† Node.js. Il passe par un "pont" (`contextBridge`) qui n'expose que des m√©thodes sp√©cifiques (`ai.chat()`, `fs.organize()`) et non l'API compl√®te.

### Q: Quelle est la structure du projet ?

**R:**

- **`src/main`** : Le Chef d'Orchestre (Node.js). Contient la logique backend, l'acc√®s BDD (`services/core/db`), les watchers (`services/fs`), et les handlers IPC qui r√©pondent aux demandes du Frontend.
- **`src/renderer`** : La Vitrine (React). Interface utilisateur, Components Shadcn, et hooks (`useChat`).
- **`src/renderer/worker`** : L'Usine Cach√©e. Contient le code sp√©cifique √† la fen√™tre invisible qui charge les mod√®les IA WebLLM.
- **`src/preload`** : La Douane. Scripts qui s'ex√©cutent avant le Renderer pour exposer des APIs s√©curis√©es via `contextBridge`.
- **`src/shared`** : Le Dictionnaire. Types TypeScript partag√©s (Interfaces `FileObject`, `Rule`, `Message`) pour garantir que tout le monde parle la m√™me langue.

### Q: Pouvez-vous tracer le chemin d'une requ√™te IA (IPC) ?

**R:**
Prenons l'exemple o√π l'utilisateur demande "Trie mes factures" :

1.  **Renderer (React)** : L'utilisateur clique. Le composant appelle `window.ai.chat("Trie mes factures")`.
2.  **Preload** : Intercepte l'appel et l'envoie via `ipcRenderer.invoke('ai:chat', ...)` au Main Process.
3.  **Main Process** : Re√ßoit la demande. Il ne fait pas le calcul lui-m√™me ! Il le relaye au **Worker** via `workerWindow.webContents.send('ai:chat', ...)`.
4.  **Worker (Hidden)** : Re√ßoit le message, fait tourner Llama 3 (WebGPU), et g√©n√®re la r√©ponse token par token.
5.  **Retour** : Le Worker renvoie les tokens au Main, qui les renvoie au Renderer via `mainWindow.webContents.send('ai:on-token')`.
    => C'est ce ping-pong qui permet √† l'interface de rester fluide pendant que le GPU travaille.

---

## ü§ñ Intelligence Artificielle (Local-First)

### Q: Pourquoi du "Local-First" ? C'est plus compliqu√© que d'appeler l'API OpenAI.

**R:**

- **Privacy (Vie Priv√©e) :** C'est un gestionnaire de fichiers personnels. Envoyer les factures ou photos d'un utilisateur dans le cloud est inacceptable niveau confidentialit√©.
- **Offline :** L'app doit marcher sans internet.
- **Co√ªt :** Pas d'abonnement API √† payer pour l'utilisateur.

### Q: Quels mod√®les utilisez-vous et pourquoi ?

**R:**

- **Llama 3 8B (via WebLLM) :** Pour le raisonnement complexe (Chat Oracle). C'est le meilleur rapport intelligence/poids actuel pour tourner sur un laptop grand public.
- **MobileBERT :** Pour la classification de texte (rapide, l√©ger). Pas besoin d'un LLM g√©ant pour savoir si un PDF est une facture.
- **ResNet-50 :** Pour la classification d'images (Computer Vision classique et efficace).

### Q: Comment g√©rez-vous le probl√®me du t√©l√©chargement des mod√®les (plusieurs Go) ?

**R:**

- Les mod√®les sont mis en cache localement apr√®s le premier t√©l√©chargement.
- On utilise des versions quantifi√©es (q4f32) pour r√©duire la taille (ex: Llama 3 ~4Go au lieu de 15Go+) sans trop perdre en pr√©cision.

---

## üíæ Donn√©es & Performance

### Q: Comment g√©rez-vous la base de donn√©es ?

**R:**

- **SQLite (via `better-sqlite3`) :** C'est le standard pour les apps locales. Fichier unique, pas de serveur √† installer.
- **Full-Text Search (FTS5) :** On utilise le module FTS de SQLite pour permettre une recherche ultra-rapide dans le contenu index√© des documents.

### Q: Si je glisse 1000 fichiers dans la DropZone, l'app plante-t-elle ?

**R:**

- Non, car le traitement est **asynchrone** et mis en file d'attente (Queue).
- L'UI est virtualis√©e (avec `react-window`) pour afficher de tr√®s longues listes sans ralentir le DOM.

---

## üêõ Difficult√©s Rencontr√©es

### Q: Quel a √©t√© le plus gros d√©fi technique ?

**R:** _(Choisis-en un vrai)_

1.  **L'int√©gration des modules natifs (`node-gyp`) :** Faire marcher `@parcel/watcher` et `better-sqlite3` sur diff√©rentes plateformes (Mac/Win) et surtout dans la CI GitHub Actions (probl√®me de compilation/SSH r√©gl√© r√©cemment).
2.  **La communication avec le Worker IA :** G√©rer l'√©tat asynchrone de l'IA (chargement, r√©ponse stream√©e token par token) et l'afficher fluidement dans l'UI via IPC √©tait complexe.

---

## üîÆ √âvolutions Futures

### Q: Que manque-t-il pour une v3.0 ?

**R:**

1.  **Support RAG (Retrieval-Augmented Generation) complet :** Permettre √† Llama 3 de "lire" vraiment tout le contenu de vos fichiers pour r√©pondre (actuellement index√© sommairement).
2.  **Plugin System :** Permettre aux devs de cr√©er leurs propres r√®gles ou connecteurs (ex: Google Drive, Dropbox).
