# DashArchive - Mod√®les IA

## üß† Vue d'Ensemble des Mod√®les

DashArchive utilise **deux mod√®les IA** avec des r√¥les distincts:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         MOD√àLES IA                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ      MOD√àLE CONVERSATIONNEL ‚îÇ   ‚îÇ      MOD√àLE CLASSIFICATION  ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ  Llama-3-8B-Instruct        ‚îÇ   ‚îÇ  BART Zero-Shot             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (q4f32_1-MLC)              ‚îÇ   ‚îÇ  (Xenova/bart-large-mnli)   ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ  üìç Localisation: Worker    ‚îÇ   ‚îÇ  üìç Localisation: Main      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  üîß Framework: Web-LLM      ‚îÇ   ‚îÇ  üîß Framework: ONNX Runtime ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚ö° Acc√©l√©ration: WebGPU    ‚îÇ   ‚îÇ  ‚ö° Acc√©l√©ration: CPU/WASM  ‚îÇ ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ
‚îÇ  ‚îÇ  Usage:                     ‚îÇ   ‚îÇ  Usage:                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Chat conversationnel     ‚îÇ   ‚îÇ  - Classifier les fichiers  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Appels d'outils          ‚îÇ   ‚îÇ  - Sugg√©rer des cat√©gories  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - R√©ponses utilisateur     ‚îÇ   ‚îÇ  - Tri automatique          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ü¶ô Mod√®le Conversationnel (Llama 3)

### Sp√©cifications

| Propri√©t√©        | Valeur                            |
| ---------------- | --------------------------------- |
| **Nom**          | `Llama-3-8B-Instruct-q4f32_1-MLC` |
| **Taille**       | ~4 GB (quantifi√© 4-bit)           |
| **Framework**    | Web-LLM (MLC AI)                  |
| **Acc√©l√©ration** | WebGPU (GPU local)                |
| **Localisation** | Worker Window (cach√©)             |

### Fichiers Impliqu√©s

```
src/renderer/
‚îú‚îÄ‚îÄ worker.html          # Page h√©bergeant le worker
‚îî‚îÄ‚îÄ src/worker/
    ‚îî‚îÄ‚îÄ ai.ts            # Script d'initialisation et chat
```

### Configuration

```typescript
// src/renderer/src/worker/ai.ts
const SELECTED_MODEL = 'Llama-3-8B-Instruct-q4f32_1-MLC'

engine = await CreateMLCEngine(SELECTED_MODEL, {
  initProgressCallback: (progress) => {
    window.api.aiWorker.sendProgress(progress)
  }
})
```

### Utilisation

Le mod√®le est utilis√© pour:

1. **Chat g√©n√©ral**: R√©pondre aux questions de l'utilisateur
2. **Appels d'outils**: G√©n√©rer du JSON pour les actions
3. **Assistant intelligent**: Comprendre l'intention de l'utilisateur

---

## üìä Mod√®le de Classification (BART)

### Sp√©cifications

| Propri√©t√©        | Valeur                         |
| ---------------- | ------------------------------ |
| **Nom**          | `Xenova/bart-large-mnli`       |
| **Type**         | Zero-Shot Classification       |
| **Framework**    | Transformers.js + ONNX Runtime |
| **Acc√©l√©ration** | WASM/CPU                       |
| **Localisation** | Main Process                   |

### Fichiers Impliqu√©s

```
src/main/services/ai/
‚îú‚îÄ‚îÄ index.ts             # AIService (singleton)
‚îî‚îÄ‚îÄ ai.test.ts           # Tests unitaires
```

### Configuration

```typescript
// src/main/services/ai/index.ts
private textModelName = 'Xenova/bart-large-mnli'

async classifyText(text: string, labels: string[]): Promise<ClassificationResult[]> {
  const result = await this.textClassifier(text, labels, {
    hypothesis_template: 'Ce document est de type {}',
    multi_label: true
  })
  return result.labels.map((label, i) => ({
    label,
    score: result.scores[i]
  }))
}
```

### Utilisation

Le mod√®le classifie les fichiers en fonction de:

- **Nom du fichier**: `facture_2024.pdf` ‚Üí "Finance"
- **Contenu (si texte)**: Analyse le texte extrait
- **Labels configur√©s**: Cat√©gories personnalis√©es par l'utilisateur

---

## ‚ö° Performance et Optimisation

### Web-LLM (Llama 3)

| Aspect                   | Optimisation                   |
| ------------------------ | ------------------------------ |
| **Premier chargement**   | ~30-60s (t√©l√©charge le mod√®le) |
| **Chargements suivants** | ~5-10s (cache local)           |
| **Inf√©rence**            | ~1-3s par r√©ponse              |
| **M√©moire GPU**          | ~4-6 GB VRAM                   |

### BART Classification

| Aspect         | Optimisation           |
| -------------- | ---------------------- |
| **Chargement** | ~2-5s                  |
| **Inf√©rence**  | ~100-500ms par fichier |
| **M√©moire**    | ~200-500 MB RAM        |

---

## üîß Fallback et Erreurs

### Si WebGPU non disponible

- Affiche un message d'erreur
- L'IA conversationnelle est d√©sactiv√©e
- La classification BART continue de fonctionner

### Si mod√®le √©choue √† charger

- Retry automatique apr√®s 5s
- Log de l'erreur
- Fallback vers r√®gles manuelles (pas d'IA)

---

## üì¶ Cache des Mod√®les

Les mod√®les sont cach√©s dans:

- **Web-LLM**: IndexedDB du navigateur (WebGPU cache)
- **ONNX**: `~/.cache/huggingface/` (Transformers.js)

Pour vider le cache:

```bash
# IndexedDB: DevTools > Application > Storage > Clear
# ONNX: rm -rf ~/.cache/huggingface/
```
